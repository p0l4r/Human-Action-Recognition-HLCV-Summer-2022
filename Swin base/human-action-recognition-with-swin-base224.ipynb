{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Dependencies","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:05:48.460293Z","iopub.execute_input":"2022-08-01T12:05:48.461011Z","iopub.status.idle":"2022-08-01T12:05:48.465549Z","shell.execute_reply.started":"2022-08-01T12:05:48.460973Z","shell.execute_reply":"2022-08-01T12:05:48.464575Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"!pip install torch_snippets torch_summary\n!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-01T12:05:48.522039Z","iopub.execute_input":"2022-08-01T12:05:48.522556Z","iopub.status.idle":"2022-08-01T12:06:07.142744Z","shell.execute_reply.started":"2022-08-01T12:05:48.522523Z","shell.execute_reply":"2022-08-01T12:06:07.141578Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torchvision import transforms, models\nfrom torch_snippets import *\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchsummary import summary \nfrom transformers import SwinForImageClassification\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport pandas as pd\n\nsns.set_theme()\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.146145Z","iopub.execute_input":"2022-08-01T12:06:07.146474Z","iopub.status.idle":"2022-08-01T12:06:07.156713Z","shell.execute_reply.started":"2022-08-01T12:06:07.146444Z","shell.execute_reply":"2022-08-01T12:06:07.155577Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"execution":{"iopub.status.busy":"2022-06-23T15:25:20.509666Z","iopub.execute_input":"2022-06-23T15:25:20.51005Z","iopub.status.idle":"2022-06-23T15:25:20.516006Z","shell.execute_reply.started":"2022-06-23T15:25:20.510018Z","shell.execute_reply":"2022-06-23T15:25:20.514754Z"}}},{"cell_type":"code","source":"DIR = \"../input/human-action-recognition-har-dataset/Human Action Recognition/\"\nTRAIN_DIR=f\"{DIR}train\"\nTEST_DIR=f\"{DIR}test\"\nTRAIN_VAL_DF = \"../input/human-action-recognition-har-dataset/Human Action Recognition/Training_set.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.158524Z","iopub.execute_input":"2022-08-01T12:06:07.158936Z","iopub.status.idle":"2022-08-01T12:06:07.167418Z","shell.execute_reply.started":"2022-08-01T12:06:07.158816Z","shell.execute_reply":"2022-08-01T12:06:07.166296Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"train_val_data=glob(TRAIN_DIR+'/*.jpg')\n# remove duplicate\ntrain_val_data.remove('../input/human-action-recognition-har-dataset/Human Action Recognition/train/Image_10169(1).jpg')\ntrain_data, val_data = train_test_split(train_val_data, test_size=0.2,\n                                       shuffle=True)\nprint('Train Size', len(train_data))\nprint('Val Size', len(val_data))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.171193Z","iopub.execute_input":"2022-08-01T12:06:07.171470Z","iopub.status.idle":"2022-08-01T12:06:07.233264Z","shell.execute_reply.started":"2022-08-01T12:06:07.171438Z","shell.execute_reply":"2022-08-01T12:06:07.232282Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(f\"{DIR}Training_set.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.234627Z","iopub.execute_input":"2022-08-01T12:06:07.235446Z","iopub.status.idle":"2022-08-01T12:06:07.259722Z","shell.execute_reply.started":"2022-08-01T12:06:07.235411Z","shell.execute_reply":"2022-08-01T12:06:07.258715Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"agg_labels = df.groupby('label').agg({'label': 'count'})\nagg_labels.rename(columns={'label': 'count'})","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.261123Z","iopub.execute_input":"2022-08-01T12:06:07.261872Z","iopub.status.idle":"2022-08-01T12:06:07.277209Z","shell.execute_reply.started":"2022-08-01T12:06:07.261836Z","shell.execute_reply":"2022-08-01T12:06:07.276267Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"ind2cat = sorted(df['label'].unique().tolist())\ncat2ind = {cat: ind for ind, cat in enumerate(ind2cat)}","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.278903Z","iopub.execute_input":"2022-08-01T12:06:07.279661Z","iopub.status.idle":"2022-08-01T12:06:07.286496Z","shell.execute_reply.started":"2022-08-01T12:06:07.279621Z","shell.execute_reply":"2022-08-01T12:06:07.285576Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"class HumanActionData(Dataset):\n    def __init__(self, file_paths, df_path, cat2ind):\n        super().__init__()\n        self.file_paths = file_paths\n        self.cat2ind = cat2ind\n        self.df = pd.read_csv(df_path)\n        self.transform = transforms.Compose([ \n            transforms.Resize([224, 224]), \n            transforms.ToTensor(),\n            # std multiply by 255 to convert img of [0, 255]\n            # to img of [0, 1]\n            transforms.Normalize((0.485, 0.456, 0.406), \n                                 (0.229*255, 0.224*255, 0.225*255))]\n        )\n    \n    def __len__(self):\n        return len(self.file_paths)\n    \n    def __getitem__(self, ind):\n        file_path = self.file_paths[ind]\n        itarget = int(fname(file_path)[6:-4])\n        target = self.df.iloc[itarget-1]['label']\n        target = self.cat2ind[target]\n        img = Image.open(file_path).convert('RGB')\n        return img, target\n    \n    def collate_fn(self, data):\n        imgs, targets = zip(*data)\n        imgs = torch.stack([self.transform(img) for img in imgs], 0)\n        imgs = imgs.to(device)\n        targets = torch.tensor(targets).long().to(device)\n        return imgs, targets\n    \n    def choose(self):\n        return self[np.random.randint(len(self))]","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.288215Z","iopub.execute_input":"2022-08-01T12:06:07.288944Z","iopub.status.idle":"2022-08-01T12:06:07.301973Z","shell.execute_reply.started":"2022-08-01T12:06:07.288907Z","shell.execute_reply":"2022-08-01T12:06:07.301104Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"train_ds = HumanActionData(train_data, TRAIN_VAL_DF, cat2ind)\ntrain_dl = DataLoader(train_ds, batch_size=128, shuffle=True,\n                      collate_fn=train_ds.collate_fn,\n                      drop_last=True)\n\nval_ds = HumanActionData(val_data, TRAIN_VAL_DF, cat2ind)\nval_dl = DataLoader(val_ds, batch_size=128, shuffle=True,\n                    collate_fn=val_ds.collate_fn,\n                    drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.303601Z","iopub.execute_input":"2022-08-01T12:06:07.304234Z","iopub.status.idle":"2022-08-01T12:06:07.339190Z","shell.execute_reply.started":"2022-08-01T12:06:07.304198Z","shell.execute_reply":"2022-08-01T12:06:07.338284Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"img, target = train_ds.choose()\nshow(img, title=ind2cat[int(target)])","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.343764Z","iopub.execute_input":"2022-08-01T12:06:07.344023Z","iopub.status.idle":"2022-08-01T12:06:07.522278Z","shell.execute_reply.started":"2022-08-01T12:06:07.344000Z","shell.execute_reply":"2022-08-01T12:06:07.521253Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"inspect(*next(iter(train_dl)), names='image, target')","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:07.523821Z","iopub.execute_input":"2022-08-01T12:06:07.524823Z","iopub.status.idle":"2022-08-01T12:06:08.623568Z","shell.execute_reply.started":"2022-08-01T12:06:07.524786Z","shell.execute_reply":"2022-08-01T12:06:08.622273Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class ActionClassifier_VGG(nn.Module):\n    def __init__(self, ntargets):\n        super().__init__()\n        VGG = models.vgg16(pretrained=True, progress=True)\n        modules = list(VGG.children())[:-1] # delete last layer\n        self.VGG = nn.Sequential(*modules)\n        for param in self.VGG.parameters():\n            param.requires_grad = False\n        \n        self.fc1 = nn.Sequential(\n            nn.Flatten(),\n            nn.BatchNorm1d(VGG.classifier[0].in_features),\n            nn.Dropout(0.4),\n            nn.Linear(VGG.classifier[0].in_features, 256),\n            nn.AdaptiveMaxPool1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.Linear(256, ntargets)\n        )\n    def forward(self, x):\n        x = self.VGG(x)\n        x = self.fc1(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:08.624834Z","iopub.execute_input":"2022-08-01T12:06:08.625198Z","iopub.status.idle":"2022-08-01T12:06:08.634759Z","shell.execute_reply.started":"2022-08-01T12:06:08.625161Z","shell.execute_reply":"2022-08-01T12:06:08.633587Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"model_base_id = \"microsoft/swin-base-patch4-window7-224-in22k\"\n# model_tiny_id = \"microsoft/swin-tiny-patch4-window7-224\"\n\nclass ActionClassifier_swin(nn.Module):\n    def __init__(self, ntargets):\n        super().__init__()\n        swin = SwinForImageClassification.from_pretrained(model_base_id)\n        modules = list(swin.children())[:-1] # delete last layer\n        self.swin = nn.Sequential(*modules)\n        for param in self.swin.parameters():\n            param.requires_grad = False\n        self.fc = nn.Sequential(\n            nn.ReLU(),\n            nn.Flatten(),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.2),\n            nn.Linear(1024, ntargets)\n        )\n    \n    def forward(self, x):\n        output = self.swin(x)[:2]\n        x = self.fc(output[1])\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:08.636260Z","iopub.execute_input":"2022-08-01T12:06:08.636611Z","iopub.status.idle":"2022-08-01T12:06:08.649267Z","shell.execute_reply.started":"2022-08-01T12:06:08.636575Z","shell.execute_reply":"2022-08-01T12:06:08.648243Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"classifier_resnet50 = ActionClassifier_VGG(len(ind2cat))\n_ = summary(classifier_resnet50, torch.zeros(32,3,224,224).to(device))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:08.650695Z","iopub.execute_input":"2022-08-01T12:06:08.651210Z","iopub.status.idle":"2022-08-01T12:06:10.248272Z","shell.execute_reply.started":"2022-08-01T12:06:08.651174Z","shell.execute_reply":"2022-08-01T12:06:10.247290Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"classifier_swin = ActionClassifier_swin(len(ind2cat))\n_ = summary(classifier_swin, torch.zeros(32,3,224,224).to(device))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:10.249786Z","iopub.execute_input":"2022-08-01T12:06:10.250379Z","iopub.status.idle":"2022-08-01T12:06:13.968024Z","shell.execute_reply.started":"2022-08-01T12:06:10.250325Z","shell.execute_reply":"2022-08-01T12:06:13.967041Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"def train(data, classifier_VGG, classifier_swin, optimizer_VGG, optimizer_swin, loss_fn):\n    imgs, targets = data\n    \n    \n#     classifier_VGG.train()\n#     outputs_VGG= classifier_VGG(imgs)\n    classifier_swin.train()\n    outputs_swin = classifier_swin(imgs)\n    outputs = outputs_swin #((outputs_resnet50 * 0.4) + (outputs_swin * 0.6)) / 2\n    loss = loss_fn(outputs, targets)\n    preds = outputs.argmax(-1)\n    acc = (sum(preds==targets) / len(targets))\n#     classifier_VGG.zero_grad()\n    classifier_swin.zero_grad()\n    loss.backward()\n#     optimizer_VGG.step()\n    optimizer_swin.step()\n    return loss, acc","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:13.969400Z","iopub.execute_input":"2022-08-01T12:06:13.969950Z","iopub.status.idle":"2022-08-01T12:06:13.977050Z","shell.execute_reply.started":"2022-08-01T12:06:13.969910Z","shell.execute_reply":"2022-08-01T12:06:13.976102Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef validate(data, classifier_VGG,classifier_swin, loss_fn):\n    imgs, targets = data\n    \n#     classifier_VGG.eval()\n#     outputs_VGG = classifier_VGG(imgs)\n    classifier_swin.eval()\n    outputs_swin = classifier_swin(imgs)\n    outputs = outputs_swin #((outputs_resnet50 * 0.4) + (outputs_swin * 0.6)) / 2\n    loss = loss_fn(outputs, targets)\n    preds = outputs.argmax(-1)\n    acc = (sum(preds==targets) / len(targets))\n    return loss, acc","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:13.978402Z","iopub.execute_input":"2022-08-01T12:06:13.979379Z","iopub.status.idle":"2022-08-01T12:06:13.991458Z","shell.execute_reply.started":"2022-08-01T12:06:13.979327Z","shell.execute_reply":"2022-08-01T12:06:13.990480Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nlog = Report(n_epochs)\nclassifier_VGG = ActionClassifier_VGG(len(ind2cat)).to(device)\nclassifier_swin = ActionClassifier_swin(len(ind2cat)).to(device)\nloss_fn = nn.CrossEntropyLoss()\noptimizer_VGG = optim.Adam(classifier_VGG.parameters())\nscheduler_VGG = optim.lr_scheduler.StepLR(optimizer_VGG, step_size=10,gamma=0.5)\noptimizer_swin = optim.Adam(classifier_swin.parameters())\nscheduler_swin = optim.lr_scheduler.StepLR(optimizer_swin, step_size=10,gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:13.993161Z","iopub.execute_input":"2022-08-01T12:06:13.993813Z","iopub.status.idle":"2022-08-01T12:06:19.539555Z","shell.execute_reply.started":"2022-08-01T12:06:13.993776Z","shell.execute_reply":"2022-08-01T12:06:19.538584Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epochs):\n    n_batch = len(train_dl)\n    for i, data in enumerate(train_dl):\n        train_loss, train_acc = train(data, classifier_VGG, classifier_swin, \n                                      optimizer_VGG, optimizer_swin, loss_fn)\n        pos = epoch + ((i+1)/n_batch)\n        log.record(pos=pos, train_loss=train_loss, \n                   train_acc=train_acc, end='\\r')\n        \n    n_batch = len(val_dl)\n    for i, data in enumerate(val_dl):\n        val_loss, val_acc = validate(data, classifier_VGG, classifier_swin, loss_fn)\n        pos = epoch + ((i+1)/n_batch)\n        log.record(pos=pos, val_loss=val_loss, val_acc=val_acc, \n                   end='\\r')\n    \n#     scheduler_VGG.step()\n    scheduler_swin.step()\n    log.report_avgs(epoch+1)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:06:19.540943Z","iopub.execute_input":"2022-08-01T12:06:19.541284Z","iopub.status.idle":"2022-08-01T12:48:03.432599Z","shell.execute_reply.started":"2022-08-01T12:06:19.541249Z","shell.execute_reply":"2022-08-01T12:48:03.431554Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"log.plot_epochs(['train_loss', 'val_loss'])","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:48:03.433918Z","iopub.execute_input":"2022-08-01T12:48:03.435640Z","iopub.status.idle":"2022-08-01T12:48:03.753265Z","shell.execute_reply.started":"2022-08-01T12:48:03.435600Z","shell.execute_reply":"2022-08-01T12:48:03.752274Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"log.plot_epochs(['train_acc', 'val_acc'])","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:48:03.754770Z","iopub.execute_input":"2022-08-01T12:48:03.755116Z","iopub.status.idle":"2022-08-01T12:48:04.086245Z","shell.execute_reply.started":"2022-08-01T12:48:03.755081Z","shell.execute_reply":"2022-08-01T12:48:04.085317Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"!mkdir saved_models\ntorch.save(classifier_resnet50.state_dict(), './saved_models/classifier_weights_resnet50.pth')\ntorch.save(classifier_swin.state_dict(), './saved_models/classifier_weights_swin.pth')","metadata":{"execution":{"iopub.status.busy":"2022-08-01T12:48:04.087862Z","iopub.execute_input":"2022-08-01T12:48:04.088488Z","iopub.status.idle":"2022-08-01T12:48:05.538026Z","shell.execute_reply.started":"2022-08-01T12:48:04.088450Z","shell.execute_reply":"2022-08-01T12:48:05.536845Z"},"trusted":true},"execution_count":117,"outputs":[]}]}